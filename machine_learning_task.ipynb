{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3a54f3b-198a-4ce7-a37b-bc5373394a1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## IMPORTS\n",
    "import seaborn as sns\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from PIL import Image\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d9b9bbe-d82b-4522-b5ac-cc546a0d5f64",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>User</th>\n",
       "      <th>Text</th>\n",
       "      <th>Hashtag</th>\n",
       "      <th>Retweets</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Replies</th>\n",
       "      <th>Source</th>\n",
       "      <th>Location</th>\n",
       "      <th>Verified_Account</th>\n",
       "      <th>Followers</th>\n",
       "      <th>Following</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1211798864656769025</td>\n",
       "      <td>2019-12-30 23:58:58+00:00</td>\n",
       "      <td>SipapuNM</td>\n",
       "      <td>Looking for an exciting job where you can ski ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;a href=\"http://instagram.com\" rel=\"nofollow\"&gt;...</td>\n",
       "      <td>20 miles SE of Taos, NM</td>\n",
       "      <td>False</td>\n",
       "      <td>3342</td>\n",
       "      <td>258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1211797371853705220</td>\n",
       "      <td>2019-12-30 23:53:02+00:00</td>\n",
       "      <td>LorettaOD1</td>\n",
       "      <td>Hail in Phoenix - no way!  New opportunity at ...</td>\n",
       "      <td>['job']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;a href=\"http://jobvite.com\" rel=\"nofollow\"&gt;Jo...</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>False</td>\n",
       "      <td>63</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1211795775363145728</td>\n",
       "      <td>2019-12-30 23:46:41+00:00</td>\n",
       "      <td>guajardo_celina</td>\n",
       "      <td>Rackspace is hiring! We are looking for Nation...</td>\n",
       "      <td>['becomearacker', 'Rackspace', 'recruiting', '...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;a href=\"http://jobvite.com\" rel=\"nofollow\"&gt;Jo...</td>\n",
       "      <td>Texas, USA</td>\n",
       "      <td>False</td>\n",
       "      <td>19</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1211793355060981767</td>\n",
       "      <td>2019-12-30 23:37:04+00:00</td>\n",
       "      <td>SteveEckert_OTD</td>\n",
       "      <td>We are #hiring Administrative Assistant in Nan...</td>\n",
       "      <td>['hiring', 'jobs', 'Nanuet']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;a href=\"http://www.ziprecruiter.com\" rel=\"nof...</td>\n",
       "      <td>Orange County, California</td>\n",
       "      <td>False</td>\n",
       "      <td>966</td>\n",
       "      <td>1569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1211792689022349315</td>\n",
       "      <td>2019-12-30 23:34:25+00:00</td>\n",
       "      <td>HireLive</td>\n",
       "      <td>We are #hiring Family Service Counselor in Irv...</td>\n",
       "      <td>['hiring', 'jobs', 'Irvine']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;a href=\"http://www.ziprecruiter.com\" rel=\"nof...</td>\n",
       "      <td>United States</td>\n",
       "      <td>False</td>\n",
       "      <td>983</td>\n",
       "      <td>1251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1211792528388841473</td>\n",
       "      <td>2019-12-30 23:33:47+00:00</td>\n",
       "      <td>HireLive</td>\n",
       "      <td>We are #hiring Inside Sales Representative in ...</td>\n",
       "      <td>['hiring', 'jobs', 'Irvine']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;a href=\"http://www.ziprecruiter.com\" rel=\"nof...</td>\n",
       "      <td>United States</td>\n",
       "      <td>False</td>\n",
       "      <td>983</td>\n",
       "      <td>1251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1211791693005099008</td>\n",
       "      <td>2019-12-30 23:30:28+00:00</td>\n",
       "      <td>HireLive</td>\n",
       "      <td>We are #hiring Community Service Counselor in ...</td>\n",
       "      <td>['hiring', 'jobs', 'Irvine']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;a href=\"http://www.ziprecruiter.com\" rel=\"nof...</td>\n",
       "      <td>United States</td>\n",
       "      <td>False</td>\n",
       "      <td>983</td>\n",
       "      <td>1251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1211790931772477440</td>\n",
       "      <td>2019-12-30 23:27:26+00:00</td>\n",
       "      <td>HireLive</td>\n",
       "      <td>We are #hiring Outside Sales Representative in...</td>\n",
       "      <td>['hiring', 'jobs', 'Irvine']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;a href=\"http://www.ziprecruiter.com\" rel=\"nof...</td>\n",
       "      <td>United States</td>\n",
       "      <td>False</td>\n",
       "      <td>983</td>\n",
       "      <td>1251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1211789520473079809</td>\n",
       "      <td>2019-12-30 23:21:50+00:00</td>\n",
       "      <td>PRGWest</td>\n",
       "      <td>We are #hiring Workday HRIS Manager  19-00454 ...</td>\n",
       "      <td>['hiring', 'jobs', 'Irvine']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;a href=\"http://www.ziprecruiter.com\" rel=\"nof...</td>\n",
       "      <td>Southern California</td>\n",
       "      <td>False</td>\n",
       "      <td>829</td>\n",
       "      <td>1015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1211788232620412929</td>\n",
       "      <td>2019-12-30 23:16:43+00:00</td>\n",
       "      <td>GhLisa</td>\n",
       "      <td>We are #hiring Restaurant Manager - Hourly Man...</td>\n",
       "      <td>['hiring', 'jobs', 'Laurel']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;a href=\"http://www.ziprecruiter.com\" rel=\"nof...</td>\n",
       "      <td>Mississippi, USA</td>\n",
       "      <td>False</td>\n",
       "      <td>89</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ID                  Timestamp             User  \\\n",
       "0  1211798864656769025  2019-12-30 23:58:58+00:00         SipapuNM   \n",
       "1  1211797371853705220  2019-12-30 23:53:02+00:00       LorettaOD1   \n",
       "2  1211795775363145728  2019-12-30 23:46:41+00:00  guajardo_celina   \n",
       "3  1211793355060981767  2019-12-30 23:37:04+00:00  SteveEckert_OTD   \n",
       "4  1211792689022349315  2019-12-30 23:34:25+00:00         HireLive   \n",
       "5  1211792528388841473  2019-12-30 23:33:47+00:00         HireLive   \n",
       "6  1211791693005099008  2019-12-30 23:30:28+00:00         HireLive   \n",
       "7  1211790931772477440  2019-12-30 23:27:26+00:00         HireLive   \n",
       "8  1211789520473079809  2019-12-30 23:21:50+00:00          PRGWest   \n",
       "9  1211788232620412929  2019-12-30 23:16:43+00:00           GhLisa   \n",
       "\n",
       "                                                Text  \\\n",
       "0  Looking for an exciting job where you can ski ...   \n",
       "1  Hail in Phoenix - no way!  New opportunity at ...   \n",
       "2  Rackspace is hiring! We are looking for Nation...   \n",
       "3  We are #hiring Administrative Assistant in Nan...   \n",
       "4  We are #hiring Family Service Counselor in Irv...   \n",
       "5  We are #hiring Inside Sales Representative in ...   \n",
       "6  We are #hiring Community Service Counselor in ...   \n",
       "7  We are #hiring Outside Sales Representative in...   \n",
       "8  We are #hiring Workday HRIS Manager  19-00454 ...   \n",
       "9  We are #hiring Restaurant Manager - Hourly Man...   \n",
       "\n",
       "                                             Hashtag  Retweets  Likes  \\\n",
       "0                                                NaN         0      1   \n",
       "1                                            ['job']         0      0   \n",
       "2  ['becomearacker', 'Rackspace', 'recruiting', '...         0      0   \n",
       "3                       ['hiring', 'jobs', 'Nanuet']         0      0   \n",
       "4                       ['hiring', 'jobs', 'Irvine']         0      0   \n",
       "5                       ['hiring', 'jobs', 'Irvine']         0      0   \n",
       "6                       ['hiring', 'jobs', 'Irvine']         0      0   \n",
       "7                       ['hiring', 'jobs', 'Irvine']         0      0   \n",
       "8                       ['hiring', 'jobs', 'Irvine']         0      0   \n",
       "9                       ['hiring', 'jobs', 'Laurel']         0      0   \n",
       "\n",
       "   Replies                                             Source  \\\n",
       "0        0  <a href=\"http://instagram.com\" rel=\"nofollow\">...   \n",
       "1        0  <a href=\"http://jobvite.com\" rel=\"nofollow\">Jo...   \n",
       "2        0  <a href=\"http://jobvite.com\" rel=\"nofollow\">Jo...   \n",
       "3        0  <a href=\"http://www.ziprecruiter.com\" rel=\"nof...   \n",
       "4        0  <a href=\"http://www.ziprecruiter.com\" rel=\"nof...   \n",
       "5        0  <a href=\"http://www.ziprecruiter.com\" rel=\"nof...   \n",
       "6        0  <a href=\"http://www.ziprecruiter.com\" rel=\"nof...   \n",
       "7        0  <a href=\"http://www.ziprecruiter.com\" rel=\"nof...   \n",
       "8        0  <a href=\"http://www.ziprecruiter.com\" rel=\"nof...   \n",
       "9        0  <a href=\"http://www.ziprecruiter.com\" rel=\"nof...   \n",
       "\n",
       "                    Location  Verified_Account  Followers  Following  \n",
       "0    20 miles SE of Taos, NM             False       3342        258  \n",
       "1                    Arizona             False         63        129  \n",
       "2                 Texas, USA             False         19         50  \n",
       "3  Orange County, California             False        966       1569  \n",
       "4              United States             False        983       1251  \n",
       "5              United States             False        983       1251  \n",
       "6              United States             False        983       1251  \n",
       "7              United States             False        983       1251  \n",
       "8        Southern California             False        829       1015  \n",
       "9           Mississippi, USA             False         89         80  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first few rows to get a feel for the data\n",
    "job_tweets_raw_df = pd.read_csv(\"../data/Job_Tweets.csv\")\n",
    "job_tweets_raw_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f64a5814-9568-454e-b36d-e4c572407823",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Filter the dataset for the selected countries\n",
    "ireland_df = job_tweets_raw_df.dropna()[job_tweets_raw_df.dropna()['Location'].str.contains(\"Ireland\")]\n",
    "germany_df = job_tweets_raw_df.dropna()[job_tweets_raw_df.dropna()['Location'].str.contains(\"Germany\")]\n",
    "france_df = job_tweets_raw_df.dropna()[job_tweets_raw_df.dropna()['Location'].str.contains(\"France\")]\n",
    "spain_df = job_tweets_raw_df.dropna()[job_tweets_raw_df.dropna()['Location'].str.contains(\"Spain\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "feb267ce-c0f4-476b-ba63-be8aa950ba30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ireland_df = ireland_df.set_index(\"Timestamp\")\n",
    "germany_df = germany_df.set_index(\"Timestamp\")\n",
    "france_df = france_df.set_index(\"Timestamp\")\n",
    "spain_df = spain_df.set_index(\"Timestamp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02130efc-9138-40f3-8166-e30b13af0453",
   "metadata": {},
   "source": [
    "<h1> Supervised Learning: </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa85133e-372d-459d-b501-fb78ca62360a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define 'high' engagement as a tweet with likes greater than the 75th percentile\n",
    "high_engagement_threshold = job_tweets_raw_df['Likes'].quantile(0.75)\n",
    "job_tweets_raw_df['High_Engagement'] = (job_tweets_raw_df['Likes'] > high_engagement_threshold).astype(int)\n",
    "\n",
    "# Now, you can use 'High_Engagement' as your target variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f2829f1-6e53-4b31-88c9-e37a3afcbdf9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8769\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.97      0.92      7801\n",
      "           1       0.83      0.56      0.67      2199\n",
      "\n",
      "    accuracy                           0.88     10000\n",
      "   macro avg       0.86      0.76      0.79     10000\n",
      "weighted avg       0.87      0.88      0.87     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "# Define 'High_Engagement' as a new target variable\n",
    "high_engagement_threshold = job_tweets_raw_df['Likes'].quantile(0.75)\n",
    "job_tweets_raw_df['High_Engagement'] = (job_tweets_raw_df['Likes'] > high_engagement_threshold).astype(int)\n",
    "\n",
    "# Features and target variable\n",
    "X = job_tweets_raw_df[['Followers', 'Following', 'Retweets']]  # example features\n",
    "y = job_tweets_raw_df['High_Engagement']  # target variable\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize classifier and grid search\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "param_grid = {'n_estimators': [100, 200, 300], 'max_depth': [5, 10, 15], 'min_samples_split': [2, 5, 10]}\n",
    "grid_search = GridSearchCV(estimator=rf_classifier, param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "y_pred = best_rf_model.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1725ad93-babd-4e70-be69-03bad4bc9d05",
   "metadata": {},
   "source": [
    "The output appears to be a classification report from a machine learning model, which includes various performance metrics. Here's how to interpret each part of the report:\n",
    "\n",
    "Precision (0 class / 1 class):\n",
    "\n",
    "For the '0' class (low engagement), the precision is 0.89, meaning that 89% of the tweets predicted as low engagement were actually low engagement.\n",
    "For the '1' class (high engagement), the precision is 0.83, indicating that 83% of the tweets predicted as high engagement were actually high engagement.\n",
    "Recall (0 class / 1 class):\n",
    "\n",
    "The recall for the '0' class is 0.97, which indicates that the model successfully identified 97% of all actual low engagement tweets.\n",
    "The recall for the '1' class is much lower at 0.56, suggesting that the model identified only 56% of all actual high engagement tweets.\n",
    "F1-Score (0 class / 1 class):\n",
    "\n",
    "The F1-score for the '0' class is 0.92, showing a strong balance between precision and recall for low engagement tweets.\n",
    "The F1-score for the '1' class is 0.67, which is decent but indicates that the model is not as effective at predicting high engagement tweets as it is at predicting low engagement tweets.\n",
    "Support (0 class / 1 class):\n",
    "\n",
    "The support is the number of actual occurrences of each class in the dataset. There were 7801 low engagement tweets and 2199 high engagement tweets.\n",
    "Accuracy:\n",
    "\n",
    "The overall accuracy of the model is 0.88, meaning it correctly predicted the engagement level for 88% of the tweets in the test set.\n",
    "Macro Avg:\n",
    "\n",
    "The macro average calculates metrics independently for each class and then takes the average, treating all classes equally. The macro average for precision, recall, and F1-score are 0.86, 0.76, and 0.79 respectively, which suggests moderate overall performance.\n",
    "Weighted Avg:\n",
    "\n",
    "The weighted average takes into account the support of each class. This means that the performance on the more frequent class (low engagement) influences the metric more. The weighted averages for precision, recall, and F1-score are all 0.87.\n",
    "Comments:\n",
    "\n",
    "The model performs well in classifying low engagement tweets, as indicated by high precision, recall, and F1-score for the '0' class.\n",
    "However, it struggles with classifying high engagement tweets, especially in terms of recall, which is only 0.56. This means it misses a significant portion of the high engagement tweets (44%).\n",
    "The imbalance in the dataset (7801 low engagement vs. 2199 high engagement) may contribute to the model's bias towards predicting low engagement more accurately.\n",
    "To improve model performance, especially for the '1' class, you may consider:\n",
    "Collecting more balanced data.\n",
    "Using oversampling techniques for the minority class or undersampling for the majority class.\n",
    "Adjusting the decision threshold to increase recall for the '1' class.\n",
    "Exploring different feature sets or more complex models that might capture the nuances of high engagement tweets better.\n",
    "Using cost-sensitive learning or modifying class weights to penalize the misclassification of the minority class more heavily.\n",
    "The high overall accuracy shows promise, but the recall for the high engagement tweets needs attention to make the model more reliable for practical use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb65b450-82f3-414c-8d85-b66573ccde43",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h1> Sentiment Analysis: </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46073cea-19d1-4552-9ddf-49302199eec7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "# Define a function to calculate sentiment\n",
    "def get_tweet_sentiment(text):\n",
    "    # Create a TextBlob object\n",
    "    analysis = TextBlob(text)\n",
    "    # Set sentiment\n",
    "    if analysis.sentiment.polarity > 0:\n",
    "        return 1  # positive sentiment\n",
    "    else:\n",
    "        return 0  # neutral or negative sentiment\n",
    "\n",
    "# Apply the function to each tweet\n",
    "job_tweets_raw_df['Sentiment'] = job_tweets_raw_df['Text'].apply(get_tweet_sentiment)\n",
    "\n",
    "# Now, you can use 'Sentiment' as your target variable for classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31427eb6-6473-4541-b170-0b12984012da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8474\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.83      0.87      5908\n",
      "           1       0.78      0.87      0.82      4092\n",
      "\n",
      "    accuracy                           0.85     10000\n",
      "   macro avg       0.84      0.85      0.84     10000\n",
      "weighted avg       0.85      0.85      0.85     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Define sentiment for each tweet\n",
    "job_tweets_raw_df['Sentiment'] = job_tweets_raw_df['Text'].apply(get_tweet_sentiment)\n",
    "\n",
    "# TF-IDF Vectorization\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000)\n",
    "X = tfidf_vectorizer.fit_transform(job_tweets_raw_df['Text'])\n",
    "y = job_tweets_raw_df['Sentiment']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Naive Bayes classifier\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = nb_classifier.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56226d03-c910-4289-86e4-f17109eb0b10",
   "metadata": {},
   "source": [
    "The output is a classification report for a sentiment analysis model. Here's an interpretation of the results:\n",
    "\n",
    "Precision (0 class / 1 class):\n",
    "\n",
    "The model has a precision of 0.90 for the '0' class, indicating that when it predicts a tweet has a neutral/negative sentiment, it is correct 90% of the time.\n",
    "For the '1' class (positive sentiment), the precision is 0.78, meaning that 78% of tweets predicted as positive are correctly classified.\n",
    "Recall (0 class / 1 class):\n",
    "\n",
    "The recall for the '0' class is 0.83, which means that the model identifies 83% of all actual neutral/negative sentiment tweets correctly.\n",
    "For the '1' class, the recall is higher at 0.87, suggesting that the model is able to identify 87% of all actual positive sentiment tweets.\n",
    "F1-Score (0 class / 1 class):\n",
    "\n",
    "The F1-score, which is a balance between precision and recall, is 0.87 for the '0' class and 0.82 for the '1' class. Both scores are relatively high, indicating a good balance between precision and recall for both sentiment classes.\n",
    "Support (0 class / 1 class):\n",
    "\n",
    "The support numbers indicate a relatively balanced dataset, with 5998 instances in the '0' class and 4092 instances in the '1' class.\n",
    "Accuracy:\n",
    "\n",
    "The overall accuracy of the model is 0.85, meaning it correctly classified the sentiment of the tweets 85% of the time across both classes.\n",
    "Macro Avg:\n",
    "\n",
    "The macro average scores are 0.84 for precision, 0.85 for recall, and 0.84 for F1-score. These values suggest that the model performs comparably on both classes without significant bias towards one class.\n",
    "Weighted Avg:\n",
    "\n",
    "The weighted average takes into account the support of each class, providing a performance metric that reflects the class distribution. With scores of 0.85 across precision, recall, and F1-score, the model shows solid performance weighted by the class distribution.\n",
    "Comments:\n",
    "\n",
    "The sentiment analysis model demonstrates strong performance in both identifying positive sentiment and distinguishing neutral/negative sentiment in tweets.\n",
    "The balanced nature of the dataset is reflected in the macro and weighted averages being very close, indicating that the model's performance is not biased by class imbalance.\n",
    "The F1-scores are high for both classes, which is desirable in a sentiment analysis context where both false positives and false negatives can be equally concerning.\n",
    "One area to consider is the slightly lower precision for positive sentiments (0.78) compared to the precision for neutral/negative sentiments (0.90), which suggests that there might be some room for improvement in correctly identifying positive sentiments.\n",
    "Given the high recall for positive sentiments (0.87), the model is robust in capturing most of the positive content, which is often a priority in sentiment analysis to understand customer satisfaction or positive feedback.\n",
    "In conclusion, the sentiment analysis model performs well in classifying sentiments from the tweets with good accuracy and balance between classes. These results can provide confidence in using the model for analyzing public sentiment on social media regarding public sector employment and earnings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d4a4c5-77f7-40ce-8abf-697a08679b93",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h1> General Notes: </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718a4527-54c5-4831-9a37-c45bffc57c1e",
   "metadata": {},
   "source": [
    "The provided Python code snippets form a crucial part of our data analytics pipeline, aimed at extracting actionable insights from the tweet dataset related to Public Sector Employment and Earnings. The first snippet focuses on identifying tweets with high user engagement, a key indicator of the content's reach and impact. The second snippet delves into sentiment analysis, categorizing the general opinion expressed in the tweets as positive or neutral/negative. These analyses serve to inform strategies for social media engagement and public sentiment monitoring.\n",
    "\n",
    "1. Supervised Learning for Engagement Prediction:\n",
    "\n",
    "Purpose:\n",
    "The goal here is to predict which public sector job tweets are likely to receive high engagement, defined by the number of 'Likes'. By identifying characteristics of highly engaged tweets, we can provide recommendations to increase the visibility and impact of future communications.\n",
    "\n",
    "Code Description:\n",
    "\n",
    "The code begins by determining a threshold for 'high engagement' based on the distribution of 'Likes'. We use the 75th percentile as a benchmark, meaning that tweets with 'Likes' above this value are considered highly engaged.\n",
    "A new binary target variable, 'High_Engagement', is created where tweets above this threshold are labeled 1 (high engagement) and all others are 0 (low engagement).\n",
    "We prepare the dataset for machine learning by selecting relevant features that might predict engagement, such as 'Followers', 'Following', and 'Retweets'.\n",
    "The dataset is split into a training set for model building and a testing set for evaluation.\n",
    "We utilize a RandomForestClassifier for its robustness and ability to handle non-linear relationships. GridSearchCV is employed to tune hyperparameters and find the best model configuration.\n",
    "The best model from the grid search is then used to make predictions on the test set.\n",
    "Finally, we evaluate the model's performance using accuracy score and a classification report, which includes precision, recall, and F1-score for both classes (high and low engagement).\n",
    "\n",
    "\n",
    "2. Sentiment Analysis:\n",
    "\n",
    "Purpose:\n",
    "The sentiment analysis model aims to classify the sentiment of each tweet as either positive or neutral/negative. This information can be vital for understanding public perception of the public sector employment landscape.\n",
    "\n",
    "Code Description:\n",
    "\n",
    "The TextBlob library is utilized to calculate the sentiment polarity of each tweet, which is a measure of the sentiment's strength and direction (positive or negative).\n",
    "We define positive sentiment as having a polarity score greater than zero and assign a corresponding label of 1, while all other tweets are labeled as 0.\n",
    "The text data is transformed into a numerical format using TfidfVectorizer, which reflects the importance of words in the context of the entire dataset.\n",
    "We use the MultinomialNB (Naive Bayes) classifier, which is particularly suited for text classification tasks due to its basis in probability.\n",
    "After training the model on the training set, we make predictions on the test set and evaluate the model using the accuracy score and a classification report.\n",
    "Conclusion:\n",
    "\n",
    "These machine learning models are instrumental in uncovering trends and patterns within the tweet dataset. By predicting engagement and analyzing sentiment, we gain valuable insights into how public sector employment is viewed and discussed on social media platforms. The findings from these models can be leveraged to optimize communication strategies, enhance public relations efforts, and monitor the effectiveness of employment campaigns. Challenges encountered, model limitations, and recommendations for further analysis are detailed in the attached appendices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33476ccb-8b73-49da-b04b-b299a4fcd7c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
